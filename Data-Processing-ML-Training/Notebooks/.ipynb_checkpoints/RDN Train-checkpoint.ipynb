{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15721,
     "status": "ok",
     "timestamp": 1701744684073,
     "user": {
      "displayName": "Pranath Reddy Kumbam",
      "userId": "13245202322626445782"
     },
     "user_tz": 300
    },
    "id": "uV8Lch-wnW32",
    "outputId": "522b2cae-fc8e-42f3-a2d0-8bf87d0a6d39"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 894,
     "status": "ok",
     "timestamp": 1701744684964,
     "user": {
      "displayName": "Pranath Reddy Kumbam",
      "userId": "13245202322626445782"
     },
     "user_tz": 300
    },
    "id": "Fltk46feoNyW",
    "outputId": "7f763611-8096-4b12-f5c5-23ed19631e2b"
   },
   "outputs": [],
   "source": [
    "cd drive/My \\Drive/Acad/ADS/Project2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9685,
     "status": "ok",
     "timestamp": 1701744694646,
     "user": {
      "displayName": "Pranath Reddy Kumbam",
      "userId": "13245202322626445782"
     },
     "user_tz": 300
    },
    "id": "1qWUa27edLZ9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define DenseLayer class, which represents a single dense layer\n",
    "class DenseLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DenseLayer, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=3 // 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([x, self.relu(self.conv(x))], 1)\n",
    "\n",
    "# Define RDB (Residual Dense Block) class\n",
    "class RDB(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, num_layers):\n",
    "        super(RDB, self).__init__()\n",
    "        self.layers = nn.Sequential(*[DenseLayer(in_channels + growth_rate * i, growth_rate) for i in range(num_layers)])\n",
    "\n",
    "        # local feature fusion\n",
    "        self.lff = nn.Conv2d(in_channels + growth_rate * num_layers, growth_rate, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # local residual learning\n",
    "        return x + self.lff(self.layers(x))\n",
    "\n",
    "# Define RDN (Residual Dense Network) class\n",
    "class RDN(nn.Module):\n",
    "    def __init__(self, num_channels=3, num_features=32, growth_rate=32, num_blocks=8, num_layers=6):\n",
    "        super(RDN, self).__init__()\n",
    "        self.G0 = num_features\n",
    "        self.G = growth_rate\n",
    "        self.D = num_blocks\n",
    "        self.C = num_layers\n",
    "\n",
    "        # shallow feature extraction\n",
    "        self.sfe1 = nn.Conv2d(num_channels, num_features, kernel_size=3, padding=3 // 2)\n",
    "        self.sfe2 = nn.Conv2d(num_features, num_features, kernel_size=3, padding=3 // 2)\n",
    "\n",
    "        # residual dense blocks\n",
    "        self.rdbs = nn.ModuleList([RDB(self.G0, self.G, self.C)])\n",
    "        for _ in range(self.D - 1):\n",
    "            self.rdbs.append(RDB(self.G, self.G, self.C))\n",
    "\n",
    "        # global feature fusion\n",
    "        self.gff = nn.Sequential(\n",
    "            nn.Conv2d(self.G * self.D, self.G0, kernel_size=1),\n",
    "            nn.Conv2d(self.G0, self.G0, kernel_size=3, padding=3 // 2)\n",
    "        )\n",
    "\n",
    "        self.output = nn.Conv2d(self.G0, 1, kernel_size=3, padding=3 // 2)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        sfe1 = self.sfe1(x)\n",
    "        sfe2 = self.sfe2(sfe1)\n",
    "\n",
    "        x = sfe2\n",
    "        local_features = []\n",
    "        for i in range(self.D):\n",
    "            x = self.rdbs[i](x)\n",
    "            local_features.append(x)\n",
    "\n",
    "        # global residual learning\n",
    "        x = self.gff(torch.cat(local_features, 1)) + sfe1\n",
    "        x = self.output(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "# Set the device to use for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Pass the model to the device\n",
    "model = RDN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "agXdpFwPPiHw",
    "outputId": "31a80eb0-7080-4ae6-e3d0-a02aea8fd715"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Notebook to train Residual Dense Net Model\n",
    "'''\n",
    "\n",
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def dice_loss(pred, target, smooth = 1e-6):\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum()\n",
    "\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - dice\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        bce = F.binary_cross_entropy(pred, target, reduction='mean')\n",
    "        dice = dice_loss(pred, target)\n",
    "        return self.alpha * bce + (1 - self.alpha) * dice\n",
    "\n",
    "# Load training data\n",
    "# Labels (Outputs)\n",
    "x_trainHR = np.load('./Data/train_mask.npy').astype(np.float32)\n",
    "# Images (Conditions)\n",
    "x_trainLR = np.load('./Data/train_img.npy').astype(np.float32)\n",
    "x_trainHR = torch.Tensor(x_trainHR)\n",
    "x_trainLR = torch.Tensor(x_trainLR)\n",
    "# Print data dimensions\n",
    "print(x_trainHR.shape)\n",
    "print(x_trainLR.shape)\n",
    "\n",
    "# Create dataset and dataloader for efficient data loading and batching\n",
    "dataset = TensorDataset(x_trainHR,x_trainLR)\n",
    "dataloader = DataLoader(dataset, batch_size=5)\n",
    "\n",
    "l = len(dataloader)\n",
    "device = \"cuda\"\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "loss_function = CombinedLoss(alpha=0.5)\n",
    "n_epochs = 500\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, 2e-3, epochs=n_epochs, steps_per_epoch=x_trainHR.shape[0])\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Starting epoch {epoch + 1}:\")\n",
    "\n",
    "    epoch_loss = 0\n",
    "    pbar = tqdm(dataloader)\n",
    "\n",
    "    for labels, images in pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Update the learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_postfix(Loss=loss.item())\n",
    "\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    print(f'Average Loss for Epoch {epoch + 1}: {avg_loss:.5f}\\n')\n",
    "\n",
    "    # Save model weights\n",
    "    torch.save(model, os.path.join(\"Weights\", f\"RDN_ckpt_1.pt\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
