{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uV8Lch-wnW32"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fltk46feoNyW"
   },
   "outputs": [],
   "source": [
    "cd drive/My \\Drive/Acad/ADS/Project2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qWUa27edLZ9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, std_init=None, dropout=0.2, batch_norm=True):\n",
    "        super(DoubleConv, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=(not batch_norm)),\n",
    "            nn.BatchNorm2d(out_channels) if batch_norm else nn.Identity(),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=(not batch_norm)),\n",
    "            nn.BatchNorm2d(out_channels) if batch_norm else nn.Identity(),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=dropout) if dropout else nn.Identity()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_val=0.2, std_init=None):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        filters = 32\n",
    "\n",
    "        self.enc1 = DoubleConv(in_channels, filters, std_init)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.enc2 = DoubleConv(filters, filters*2, std_init)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.enc3 = DoubleConv(filters*2, filters*4, std_init)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.enc4 = DoubleConv(filters*4, filters*8, std_init)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.enc5 = DoubleConv(filters*8, filters*16, std_init)\n",
    "        self.pool5 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.bottleneck = DoubleConv(filters*16, filters*32, std_init)\n",
    "\n",
    "        self.up5 = nn.ConvTranspose2d(filters*32, filters*16, kernel_size=2, stride=2)\n",
    "        self.dec5 = DoubleConv(filters*32, filters*16, std_init, dropout_val)\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(filters*16, filters*8, kernel_size=2, stride=2)\n",
    "        self.dec4 = DoubleConv(filters*16, filters*8, std_init, dropout_val)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(filters*8, filters*4, kernel_size=2, stride=2)\n",
    "        self.dec3 = DoubleConv(filters*8, filters*4, std_init, dropout_val)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(filters*4, filters*2, kernel_size=2, stride=2)\n",
    "        self.dec2 = DoubleConv(filters*4, filters*2, std_init, dropout_val)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(filters*2, filters, kernel_size=2, stride=2)\n",
    "        self.dec1 = DoubleConv(filters*2, filters, std_init, dropout_val)\n",
    "\n",
    "        self.final = nn.Conv2d(filters, out_channels, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(self.pool1(enc1))\n",
    "        enc3 = self.enc3(self.pool2(enc2))\n",
    "        enc4 = self.enc4(self.pool3(enc3))\n",
    "        enc5 = self.enc5(self.pool4(enc4))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool5(enc5))\n",
    "\n",
    "        dec5 = self.dec5(torch.cat((self.up5(bottleneck), enc5), 1))\n",
    "        dec4 = self.dec4(torch.cat((self.up4(dec5), enc4), 1))\n",
    "        dec3 = self.dec3(torch.cat((self.up3(dec4), enc3), 1))\n",
    "        dec2 = self.dec2(torch.cat((self.up2(dec3), enc2), 1))\n",
    "        dec1 = self.dec1(torch.cat((self.up1(dec2), enc1), 1))\n",
    "\n",
    "        return self.sigmoid(self.final(dec1))\n",
    "\n",
    "# Usage\n",
    "model = UNet(in_channels=3, out_channels=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "id": "agXdpFwPPiHw"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Notebook to train UNet model for segmentation of Sentinel data\n",
    "'''\n",
    "\n",
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def dice_loss(pred, target, smooth = 1e-6):\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum()\n",
    "\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - dice\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        bce = F.binary_cross_entropy(pred, target, reduction='mean')\n",
    "        dice = dice_loss(pred, target)\n",
    "        return self.alpha * bce + (1 - self.alpha) * dice\n",
    "\n",
    "# Load training data\n",
    "# Labels (Outputs)\n",
    "x_trainHR = np.load('./Data/train_mask.npy').astype(np.float32)\n",
    "# Images (Conditions)\n",
    "x_trainLR = np.load('./Data/train_img.npy').astype(np.float32)\n",
    "x_trainHR = torch.Tensor(x_trainHR)\n",
    "x_trainLR = torch.Tensor(x_trainLR)\n",
    "# Print data dimensions\n",
    "print(x_trainHR.shape)\n",
    "print(x_trainLR.shape)\n",
    "\n",
    "# Create dataset and dataloader for efficient data loading and batching\n",
    "dataset = TensorDataset(x_trainHR,x_trainLR)\n",
    "dataloader = DataLoader(dataset, batch_size=5)\n",
    "\n",
    "l = len(dataloader)\n",
    "device = \"cuda\"\n",
    "model = UNet(in_channels=3, out_channels=1).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "loss_function = CombinedLoss(alpha=0.5)\n",
    "epochs = 500\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Starting epoch {epoch + 1}:\")\n",
    "\n",
    "    epoch_loss = 0\n",
    "    pbar = tqdm(dataloader)\n",
    "\n",
    "    for labels, images in pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_postfix(Dice_Loss=loss.item())\n",
    "\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    print(f'Average Loss for Epoch {epoch + 1}: {avg_loss:.5f}\\n')\n",
    "\n",
    "    # Save model weights\n",
    "    torch.save(model, os.path.join(\"Weights\", f\"UNet_ckpt_1.pt\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
