{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uV8Lch-wnW32"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fltk46feoNyW"
   },
   "outputs": [],
   "source": [
    "cd drive/My \\Drive/Acad/ADS/Project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjNwP9r2esWY"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Contracting Path\n",
    "        self.enc1 = self.conv_block(3, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.enc4 = self.conv_block(256, 512)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        # Expansive Path\n",
    "        self.up3 = self.upconv_block(512, 256)\n",
    "        self.dec3 = self.conv_block(512, 256)\n",
    "        self.up2 = self.upconv_block(256, 128)\n",
    "        self.dec2 = self.conv_block(256, 128)\n",
    "        self.up1 = self.upconv_block(128, 64)\n",
    "        self.dec1 = self.conv_block(128, 64)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def upconv_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Contracting Path\n",
    "        e1 = self.enc1(x)\n",
    "        p1 = self.pool(e1)\n",
    "        e2 = self.enc2(p1)\n",
    "        p2 = self.pool(e2)\n",
    "        e3 = self.enc3(p2)\n",
    "        p3 = self.pool(e3)\n",
    "        e4 = self.enc4(p3)\n",
    "\n",
    "        # Expansive Path\n",
    "        up3 = self.up3(e4)\n",
    "        merge3 = torch.cat([up3, e3], dim=1)\n",
    "        d3 = self.dec3(merge3)\n",
    "\n",
    "        up2 = self.up2(d3)\n",
    "        merge2 = torch.cat([up2, e2], dim=1)\n",
    "        d2 = self.dec2(merge2)\n",
    "\n",
    "        up1 = self.up1(d2)\n",
    "        merge1 = torch.cat([up1, e1], dim=1)\n",
    "        d1 = self.dec1(merge1)\n",
    "\n",
    "        out = self.out_conv(d1)\n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "id": "agXdpFwPPiHw"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Notebook to train UNet for segmentation\n",
    "'''\n",
    "\n",
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def dice_loss(pred, target, smooth = 1e-6):\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum()\n",
    "\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - dice\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        bce = F.binary_cross_entropy(pred, target, reduction='mean')\n",
    "        dice = dice_loss(pred, target)\n",
    "        return self.alpha * bce + (1 - self.alpha) * dice\n",
    "\n",
    "# Load training data\n",
    "# Labels (Outputs)\n",
    "x_trainHR = np.load('./Data/unet/train_labels.npy').astype(np.float32)\n",
    "# Images (Conditions)\n",
    "x_trainLR = np.load('./Data/unet/train_images.npy').astype(np.float32)\n",
    "x_trainHR = torch.Tensor(x_trainHR)\n",
    "x_trainLR = torch.Tensor(x_trainLR)\n",
    "# Print data dimensions\n",
    "print(x_trainHR.shape)\n",
    "print(x_trainLR.shape)\n",
    "\n",
    "# Create dataset and dataloader for efficient data loading and batching\n",
    "dataset = TensorDataset(x_trainHR,x_trainLR)\n",
    "dataloader = DataLoader(dataset, batch_size=5)\n",
    "\n",
    "l = len(dataloader)\n",
    "device = \"cuda\"\n",
    "model = UNet().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "loss_function = CombinedLoss(alpha=0.5)\n",
    "epochs = 500\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Starting epoch {epoch + 1}:\")\n",
    "\n",
    "    epoch_loss = 0\n",
    "    pbar = tqdm(dataloader)\n",
    "\n",
    "    for labels, images in pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_postfix(Dice_Loss=loss.item())\n",
    "\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    print(f'Average Loss for Epoch {epoch + 1}: {avg_loss:.5f}\\n')\n",
    "\n",
    "    # Save model weights\n",
    "    torch.save(model, os.path.join(\"Weights\", f\"UNet_ckpt_2.pt\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
